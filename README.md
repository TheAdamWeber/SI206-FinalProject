# SI206-FinalProject
This program scrapes the current top posts on reddit and displays useful visualizations related to these posts, including the ability to view tweets related to the post.

## API Setup

### reddit API Keys 
The reddit API keys are generated by creating a new application <a href='https://www.reddit.com/prefs/apps/'>here</a>. The following steps are required to generate the keys:
<ol>
<li> Click create (another) app </li>
<li> Select "web app" for the application type </li>
<li> Fill in a name (i.e. "reddit top post scraper") </li>
<li> Provide a description </li>
<li> Leave about url blank </li>
<li> Use "http://localhost:5000/validate" for the redirect uri </li>
<li> Click create app </li>
</ol>

Once the app is created, the app is available on the same page under "developed applications." The keys can now be foundwhen the "edit" button is pressed in the bottom left corner of the application box.

<ul>
<li>CLIENT_ID: This is the key found directly under the title of the application and "web app"</li>
<li>CLIENT_SECRET: This is the key labeled "secret" when the edit button is pressed on the application.</li>
<li>USER_AGENT: Description of the application (Example: "application to scrape top posts on reddit")</li>
</ul>

### Twitter API Keys
The Twitter api keys are generated when creating a new application <a href='https://apps.twitter.com/app/new'>here</a>. The following steps are required to generate the keys:
<ol>
<li>Fill in the application details with a name and description similar to the ones used on reddit.</li>
<li>Fill in the website using your website or a placeholder.</li>
<li>Check the Twitter Developer Agreement</li>
<li>Click Create your Twitter application</li>
<li>Save the consumer key and the consumer secret for secret_data.py</li>
<li>Next click "Create my access token" under Token Actions.</li>
<li>Save the access key and access secret for secret_data.py</li>
</ol>
The application is now created and available for use. The following api keys can now be entered in secret_data.py:
<ul>
<li>TWITTER_CONSUMER_KEY</li>
<li>TWITTER_CONSUMER_SECRET</li>
<li>TWITTER_ACCESS_KEY</li>
<li>TWITTER_ACCESS_SECRET</li>
</ul>

## Setting up the Program
To setup the application, create a virtual environment and download the dependencies from requirements.txt.
## Description of Code
Important functions:
<ul>
<li>retireve_data(cache, limit): Retreives data from reddit and allow the user to specify whether to use cached data or retireve new data with the number of posts specified by the limit.</li>
<li>populate_reddit_data(name): Loads data from file 'name' and populates the 'Posts' table in the reddit.db database.</li>
<li>get_reddit_data(sort): Returns a list of data queried from the 'Posts' table with the sort specified by the input.</li>
<li>populate_tweets_for_post(post_title, post_id): Populates the 'Tweets' table with tweets related to a specific reddit post using a forein key relation specified by the reddit post id.</li>
<li>get_tweet_data(post_id): Gets tweets sorted by most favorites according to the reddit post id.</li>
</ul>
Data structures:
<ul>
<li>Tweet class: Used to store all the properties related to a Tweet before they are populated in the database.</li>
<li>reddit list of dictionaries: Data retrieved from reddit is first stored in a list called lis which is a list of dictionaries containing each post retrieved from the PRAW api</li>
<li>Both the reddit and Twitter data is stored in .json files for caching</li>
</ul>

## Running the Program (User Guide)
The program can be started by running the command "python app.py". To view the Flask application, visit the url specified by Flask in your browser of choice. Once the web application is open, the first step is to validate your reddit account. After doing so, you can start scraping reddit using new data or cached data. After successfully retrieving the data, a list of the different visualization options will be available.
